import gradio as gr
from transformers import pipeline, set_seed, AutoTokenizer, AutoModelForCausalLM

def setup_model(model_name):
    """
    Initialise et configure le mod√®le pour la g√©n√©ration de texte.
    """
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForCausalLM.from_pretrained(model_name)
    generator = pipeline('text-generation', model=model, tokenizer=tokenizer)
    set_seed(42)  # Assurer la reproductibilit√©
    return generator

def generate_content(model_name, context, prompt, creativity_level, tone, output_length):
    """
    Utilise un mod√®le LLM sp√©cifi√© pour g√©n√©rer du contenu bas√© sur un contexte et un prompt donn√©s.
    Les param√®tres suppl√©mentaires permettent de personnaliser la sortie g√©n√©r√©e.
    """
    generator = setup_model(model_name)
    
    # Adaptation du prompt avec le contexte
    full_prompt = f"{context}\n\n{prompt}"
    
    # G√©n√©ration du contenu
    generated_outputs = generator(full_prompt, max_length=output_length, num_return_sequences=1,
                                  temperature=creativity_level)
    
    # Extraction et formatage du texte g√©n√©r√©
    generated_text = generated_outputs[0]['generated_text']
    if tone == "Formel":
        generated_text = generated_text.replace('!', '.')
    elif tone == "Ludique":
        generated_text = f"üòÑ {generated_text} üòÑ"

    return generated_text

# Construction de l'interface Gradio
with gr.Blocks() as app:
    gr.Markdown("## Interface d'Augmentation du Contexte et Cr√©ation de Contenu Enrichi")

    with gr.Group():
        with gr.Tab(label="Contexte R√©cup√©r√©"):
            retrieved_context = gr.Textbox(label="Contexte R√©cup√©r√©", placeholder="Le contexte r√©cup√©r√© s'affiche ici...", lines=6)
        with gr.Tab(label="Cr√©ez votre prompt"):
            prompt_creation = gr.Textbox(label="Cr√©ez votre prompt", placeholder="Entrez votre prompt ici...", lines=4)

    with gr.Group():
        model_name = gr.Dropdown(label="S√©lectionnez un mod√®le LLM", choices=["gpt2", "EleutherAI/gpt-neo-2.7B"], value="gpt2")
        creativity_level = gr.Slider(minimum=0.5, maximum=1.0, step=0.01, label="Niveau de cr√©ativit√©", value=0.7)
        tone = gr.Radio(choices=["Formel", "Informel", "Ludique"], label="Tonalit√©", value="Informel")
        output_length = gr.Number(label="Longueur de Sortie", value=150, step=10)

    generate_button = gr.Button("G√©n√©rer le Contenu")
    generated_content_display = gr.Textbox(label="Contenu G√©n√©r√©", placeholder="Le contenu g√©n√©r√© s'affichera ici...", lines=10)

    generate_button.click(
        fn=generate_content,
        inputs=[model_name, retrieved_context, prompt_creation, creativity_level, tone, output_length],
        outputs=generated_content_display
    )

if __name__ == "__main__":
    app.launch()
